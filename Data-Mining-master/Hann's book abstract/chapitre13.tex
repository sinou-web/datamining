\documentclass[12pt,a4paper,oneside]{book}
\usepackage[top=2.5cm, bottom=3cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[titletoc,title]{appendix}
\usepackage[linewidth=1pt]{mdframed}
\usepackage{framed}
\usepackage{listings}
\usepackage{smartdiagram}
\usepackage{smartdiagram}
\usepackage{varwidth}
\usesmartdiagramlibrary{additions}
\lstdefinestyle{customc}{
	belowcaptionskip=1\baselineskip,
	breaklines=true,
	frame=L,
	xleftmargin=\parindent,
	language=C,
	showstringspaces=false,
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=\bfseries\color{green!40!black},
	commentstyle=\itshape\color{purple!40!black},
	identifierstyle=\color{blue},
	stringstyle=\color{orange},
}

\lstdefinestyle{customasm}{
	belowcaptionskip=1\baselineskip,
	frame=L,
	xleftmargin=\parindent,
	language=[x86masm]Assembler,
	basicstyle=\footnotesize\ttfamily,
	commentstyle=\itshape\color{purple!40!black},
}

\lstset{escapechar=@,style=customc}

\lstset{
	literate=%
	{à}{{\'a}}1
	{í}{{\'i}}1
	{é}{{\'e}}1
	{è}{{\`e}}1
	{ý}{{\'y}}1
	{ú}{{\'u}}1
	{ó}{{\'o}}1
	{ě}{{\v{e}}}1
	{š}{{\v{s}}}1
	{č}{{\v{c}}}1
	{ř}{{\v{r}}}1
	{ž}{{\v{z}}}1
	{ď}{{\v{d}}}1
	{ť}{{\v{t}}}1
	{ň}{{\v{n}}}1
	{ů}{{\r{u}}}1
	{Á}{{\'A}}1
	{Í}{{\'I}}1
	{É}{{\'E}}1
	{Ý}{{\'Y}}1
	{Ú}{{\'U}}1
	{Ó}{{\'O}}1
	{Ě}{{\v{E}}}1
	{Š}{{\v{S}}}1
	{Č}{{\v{C}}}1
	{Ř}{{\v{R}}}1
	{Ž}{{\v{Z}}}1
	{Ď}{{\v{D}}}1
	{Ť}{{\v{T}}}1
	{Ň}{{\v{N}}}1
	{Ů}{{\r{U}}}1
}
%\usepackage[french]{babel}
%\select@language{french}
\usepackage{hyperref}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\usepackage{array}
\usepackage{makecell}
\usepackage{gensymb}
\renewcommand\theadalign{cb}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}

\usepackage{fancyhdr}
\renewcommand{\chaptername}{Chapitre}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{color}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{float}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{wrapfig}
%\captionsetup[table]{name=Figure}

%\usepackage[french,Algorithme]{algorithm}
%\renewcommand{\thealgorithm}{}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\usepackage{color}

\renewcommand{\bibname}{Bibliographie}
%\usepackage[usenames,dvipsnames]{xcolor}
%\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\renewcommand{\contentsname}{Table des matières}
\renewcommand{\listtablename}{Listes des tableaux}
\renewcommand{\listfigurename}{Listes des figures}
\renewcommand{\appendixname}{Annexe}
%\captionsetup[table]{name=tableau}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\setcounter{secnumdepth}{4}
\usepackage{titlesec}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
%\usepackage[noend]{algpseudocode}
\pagestyle{fancy}
\lhead{\leftmark}
\rhead{}
%\cfoot{center of the footer!}
\renewcommand{\headrulewidth}{0.4pt}
\definecolor{Titre}{rgb}{0.09,0.21,0.36}
\definecolor{Sous-titre}{rgb}{0.31,0.51,0.74}
\usepackage{titlesec}
%\usepackage[linesnumbered,algoruled,french,onelanguage]{algorithm2e}
\usepackage{color}
%\setlist[itemize]{label=\textbullet}
\usepackage[linesnumbered,algoruled,french,onelanguage]{algorithm2e}


\lstset{
language=C,                   % choix du langage (de programmation).
keywordstyle=\color{blue},      % choix de la couleur des mots clés.
stringstyle=\color{red},        % choix de la couleur des string.
commentstyle=\color{green},     % choix de la couleur des commentaire.
basicstyle=\normalsize,     % taille de la police du code
% numbers=left,                   % placer le numéro de chaque ligne à gauche (on peut choisir à droite, ou ne pas mettre cette option pour aucun numéro de ligne).
numberstyle=\normalsize,        % taille de la police des numéros.
numbersep=0pt,                  % distance entre le code et sa numérotation.
showstringspaces=false,         % pour ne pas afficher les espaces comme des caractères .
breaklines=true,                % couper la ligne si la ligne du code est trop longue.
}
\begin{document}
\def\reportnumber{1}
%\input{../../TP0/front_page}
	\pagenumbering{gobble}
	\pagenumbering{gobble}
    \chapter{Introduction}
    % \section{Pourquoi le Data mining }
    l'apparition est du  à la richesse du monde actuel en données et l'abondance  de ces derniers  mais paradoxalement pauvre  en information ,  la croissance exponentielle en quantité de données qui sont stockées et collectées sont à l'origine de l'incapacité humaine à gérer ce flux  de données et en extraire des connaissances pertinentes sans une utilisation d'outils adéquates, le besoin en exploration de données grandit et.
    
    \section{Qu'est ce que le Data mining}
    Le Data mining ou fouille de données est le processus d'exploration et d'extraction de connaissances ou de motifs à partir d'un volume conséquent de données en utilisant des outils ,
    le processus comporte plusieurs étapes qui sont les suivantes :
    \subsection{Nettoyage de données}
    ceci consiste à éliminer les données bruitées 
    \subsection{Integration de données}
    
    \subsection{Sélection de données}
    on récupéré les données pertinentes de la base de données pour qu'elles puissent
		par la suite être utilisé lors de l'analyse
	\subsection{Transformation de données}
	La transformation consiste à faire des opérations d'agrégation , normalisation ou bien un résumé à fin de rendre les données sous une formes approprié  pour l'exploration minière .  
	\subsection{Data mining}
	c'est l'application de méthodes intelligentes pour l'extraction des modèles ou motifs de données 
	\subsection{Évaluation des motifs}
	c'est une Identification des motifs pertinents représentant le mieux la connaissance
	
	\subsection{Présentation de données}
	c'est la visualisation et présentation des connaissances aux utilisateurs.
    \section{Les types de données qui peuvent être utilisés pour le data mining }
    Ils existent différent types de données sur les quelles le data mining peut opérer , pour cella la seule condition suffisante est que ces données doivent avoir du sens , parmi elles :
    \subsection{Les bases de données}
     c'est une collection de données interdépendantes  un logiciel  (système de gestion de base de données SGBD) permettant de gérer ,accéder et sécuriser ces données, les données sont sous forme de tables relationnelles  suivant un certain format, chaque table comporte des colonnes qui appelées attribues et les lignes sont les tuples  ou instance ( un objet ).
     
     
   \subsection{Les entrepôts de données}
   
   un entrepôt de données est un référentiel des informations collectées à partir de sources multiples, stockées sous une base de données unifiée.
   ce schéma est résidant généralement sur un site unique, l'entrepôt de données est construit via un processus de nettoyage des données, d’intégration, de transformation, de chargement et de
   rafraîchissement des données odiques et généralement modélisé par une structure de données multidimensionnelle, appelée
   cube de données
   dans lequel chaque
   dimension représente un ou plusieurs attributs ,ce cube de données fournit une vue multidimensionnelle des données et permet
   le précalcul et l'accès rapide aux données résumées.
   \subsection{Base données transactionnelles }
    une base de données transactionnelles se compose principalement de transactions mais peut aussi contenir des tables supplémentaires contenant des informations sur les transactions existantes .
   \subsection{Autres types de données}
   il existe d'autres types de données
   sous formes et  structures polyvalentes et assez différentes
   sémantiquement. Ces types de données peuvent être vus dans de nombreuses applications: liées au temps
   données séquentielles,
    les flux de données , données spatiales (cartes, par exemple), données de conception technique , hypertexte et multi-données multimédia (y compris texte, image, vidéo et audio), graphique et données en réseau
    et le Web . Ces applications apportent de nouveaux
   défis, tel que la gestion des données contenant des structures spéciales et une sémantique spécifique
    \section{Quels sont les motifs qui peuvent être extraits ?}
     \subsection{Classe/Concept Description: Caractérisation
     et Discrimination}
     Les entrées de données peuvent être associé à des classes ou des concepts , ces classes et concepts sont décrites selon un mécanisme 
    de \textbf{caractérisation des données}, en résumant les données de la classe étudiée (souvent appelé le classe cible) en termes généraux, ou \textbf{discrimination des données}, par comparaison de la classe  cible avec une ou plusieurs classes comparatives (souvent appelée la en contraste Des classes),ou une composition des deux techniques. 
    le résultat de caractérisation donnent en sortie des statistiques résumé en diagramme à barres
    ,
    courbes , ou bien des règles de généralisations , alors que la discrimination donne en sortie des règles de discriminations.
    \subsection{Motifs fréquents , associations et corrélations} 
     Les motifs fréquents sont des modèles qui apparaissent de façon assez répétitive dans les données, il existe plusieurs types tel que  les ensembles d'éléments fréquent,des sous-projets ou encore des sous-structures fréquentes séquentiels et structurés  de différentes formes  (graphes,arbre ...),    
     \textbf{Association}
     les règles d’association sont des règles exprimés  en prédicat permettant de découvrir une relation entre différente variable (attributs) dans une large base de données . \\
  \textbf{correlation } est une relation  liant deux ou plusieurs attributs associées dans un large volume de données.
    \subsection{Classification et régression pour une analyse prédictive}
    La Classification
    est le processus de recherche d'un
    modèle
    (ou fonction) qui décrit et distingue
   des classes de données ou des concepts.
    ils sont utilisé
    pour prédire l'étiquette de classe d'objets pour laquelle l'étiquette de classe est inconnue 
   
 \textbf{  Régression}
 régression modélise des fonctions à valeurs continue , c'est une méthode statistique  très utilisée pour prédire les données manquantes ou valeurs indisponibles de données numériques
 plutôt que des étiquettes de classe (discrètes).
 \subsection{clustering}
 Le clustering est le processus de regroupement des objets (des données) selon un degré de similarité entre eux, tel que  on maximise la similarité entre les membres d'un même groupe  tout en minimisant la similarité  entres les membres  de groupes différents (dissimilarité) . ça permet une meilleure organisation de données où chaque groupe présentent une classe ,catégorie ...
 \subsection{Outlier (valeurs aberrantes )}
Ce sont des objets non conformes au comportement ou au modèle général des données. Ces objets de données sont valeurs aberrantes. ces objets peuvent être vu comme du bruit ou des exceptions .
\subsection{Ce qui fait qu'un modèle est intéressent}
Il est clair que le data mining peut générer des milliers de modèles et motifs mais l'utilité des modèles restent relatif selon le besoin , à noter que les modèles sont coûteux à produire donc il faudrait s'intéresser qu'aux modèles pertinents, pour qualifier un modèle de tel adjectif il faut :
\begin{itemize}
\item qu'il soit facile à assimiler et comprendre par ces utilisateurs
\item qu'il procure une validation de nouvelles données ou d'essai avec un certain degré de certitude
\item utile et intéressent dans le sens ou il valide ce que l'utilisateur cherche à confirmer ceci donnera naissance à DES CONNAISSANCES
\end{itemize}

.
    \section{Quelles genre de technologies sont appliquées et utilisées dans le data mining ?}
    \subsection{Statistique}
    les statistiques étudient la collection, l'analyse, l'interprétation ou l'explication et la présentation de données.UNE modèle statistique est un ensemble de fonctions mathématiques décrivant le comportement de les objets d'une classe cible en termes de variables aléatoires et leurs distributions . on peut citer la moyenne , la médian , la variance et l'écart type.
    
    \subsection{Machine learning (apprentissage automatique)}
    Apprentissage machine étudie comment les ordinateurs peuvent apprendre basé sur des données.
    Un domaine de recherche principal concerne les programmes informatiques qui apprennent automatiquement  à reconnaître des modèles complexes et prendre des décisions intelligentes basées sur des données. 
    on distingue deux types d'apprentissage supervisé (prédire une classe )et non supervisé (clustering par exemple ) ,Semi-supervisé ,active learning 
    \subsection{Système de base de données et entrepôts de données}
    La recherche de systèmes de bases de données se concentre sur la création, la maintenance et l'utilisation de bases de données pour les organisations et les utilisateurs .
    ces systèmes sont utilisé pour les raisons suivantes :
    les modèles de données, les langages de requête, le traitement des requêtes,méthodes d’optimisation, stockage de données et méthodes d’indexation et d’accès qui permet une meilleure exploration de données.
    
    on note aussi  l'entrepôt qui consolide
    les données dans un espace multidimensionnel pour former des cubes de données facilitant ainsi leurs explorations .
    
    \subsection{Recherche d'information}
    recherche d'information(IR) est la science de la recherche de documents ou d'informations dans les documents.ils peuvent être du texte ou du multimédia et peuvent résider sur le Web .La recherche d'informations suppose que  les données sous recherche sont non structurées et les requêtes sont formées principalement par des mots-clés.
    
    \section{Quelles sont les genres d'applications ciblé par le data mining}
     \subsection{Business intelligence}
     La technologie de l'intelligence d'entreprise  (BI) fournit des informations historiques, actuelles et
     vues prédictives des opérations commerciales. 
     ceci en incluant les rapports, l'analyse en ligne
     traitement, gestion des performances de l'entreprise, veille concurrentielle, analyse comparative et analyse prédictive de comportement des clients par exemple .
     \subsection{Web  Search engine (Moteur de recherche sur le web)}
     Un Moteur de recherche Web est un serveur informatique spécialisé dans la recherche des informations sur le Web , les résultats de la recherche d’une requête utilisateur sont souvent renvoyés sous forme de liste,les types des résultats peuvent consister en des pages Web, des images et d’autres types de fichiers.
    \section{Les problèmes qui font face au data mining}
    Il y a beaucoup de défis en jeux de la recherche en exploration de données:
    \begin{itemize}
    \item  La méthodologie minère
    \item Interaction avec l'utilisateur
    \item  L'efficacité , l'évolutivité, et la gestion de diverses types de données
    \end{itemize}
 
    \chapter{Prétraitement des données}
    \section{Qualité des données : Pourquoi faire du prétraitement sur nos données ?}
    On dira que les données sont de qualité si elles répondent aux exigences suivantes :
    \begin{itemize}
  
    \item l'exactitude
    \item  exhaustivité
      \item complétude
      \item  cohérence
      \item actualité (évolutif dans le temps)
      \item crédibilité et interprétabilité.
  
    \end{itemize}    
   
     Mais avoir des données de qualité n'est pas chose facile , dans le monde réel beaucoup de facteurs rentrent en jeux pour compromettre  la qualité des données tel que :
     \begin{itemize}
        \item  valeurs manquantes (donnée incomplète ) dans les tuples de données 
         \item  valeurs aberrantes (date de naissance 1700 par exemple "bruité") 
        \item inconsistance ou encore des valeurs dupliquées . 
       
     \end{itemize} 
    
    Si alors on plonge  directement dans l'exploration de nos données sans prêter attention à ces inconvenants là, la qualité des motifs ou modèles  sera affectés directement  ce qui causera un manque de crédibilité et de confiance dans ces derniers qui risquent être erronés.
    
    \section{Data Cleaning}
    L'une des principales approches de prétraitement des données , qui essaye de proposer des solutions aux différents problèmes citées plus .
    
    \subsection{Valeurs manquantes}
    Il existe diverse méthodes pour gérer les valeurs manquantes des données parmi elles :
    \subsubsection{Ignorer le tuple}
    cela consiste à renoncer à l'utilisation du tuple alors que ce dernier peut s'avérer intéressent par la suite, cette solution n'est efficace si la majorité de nos données souffrent d'un manque de valeurs d'un attribut ou deux .
    \subsubsection{Remplir les valeurs manquantes manuellement}
    Si la taille de nos données est conséquente cette méthode devient infaisable (elle prend énormément de temps) .
    \subsubsection{Utilisation d'une valeur globale pour remplir les valeurs manquantes}
    son inconvénient majeur est que lors de la fouille ou l'exploration ce genre de  valeurs globales peuvent être prise pour des concepts intéressent .
    \subsubsection{Utilisation d'une mesure de la tendance centrale de l’attribut (par exemple, la moyenne ou la médiane)}
    \subsubsection{Utilisez l'attribut moyenne ou médiane pour tous les échantillons appartenant à la même classe que
    le tuple donné }
    \subsubsection{Utilisation de la valeur la plus probable}
    ceci peut être fait grâce à la fonction de régression  , arbre de décision ou encore  l'algorithme naïf de bayes,c'est généralement la technique la plus utilisée  .
    
    
    \subsection{Les données bruitées ou erronées ( Noisy data)}
     Les données bruitées sont des données qui manquent d'incohérence comme des valeurs aberrantes ,plusieurs techniques ont été mise au point pour faire face à ce genre de problème ,on citera:
    \subsubsection{Binning (nettoyer en enlevant des valeurs)}
	    Binning se repose principalement sur le trie des valeurs des données puis il effectuera un partitionnement uniforme  de façon à voir la même taille pour chaque partition ,ce qui permettra de consulter les voisins des valeurs erronées (une recherche locale) , le binning choisira par la suite de remplacer les valeurs aberrantes par la moyenne de la partition ou la médiane ou encore par le min si la valeur est plus proche du celui ci sinon par le max de l'intervalle de la  partition (le plus proche voisin).
	    
	    \subsubsection{Régression}
	     Afin de remplacer les valeurs erronés on peut faire appelle à une fonction de régression linéaire 
	    qui inclut deux variables (attributs ) on donnera alors une valeur d'attribut pour prédire l'autre.
	      \begin{equation*}
	    	      F(attribut_1)=attribut_2
	    	      \end{equation*}
	     ou bien une fonction de régression de dimension trois ou plus ou plusieurs attributs sont mise en jeux .
	       \begin{equation*}
	     	      F(attribut_1,attribut_2,....,attribut_n)=attribut_j  \end{equation*}
    \subsubsection{Analyse des outlier}
     en utilisant le clustering 
     \subsection{Data Cleaning comme un processus}
     On peut résumer le nettoyage de données en des étapes élémentaires qui sont les suivantes:
     
    \textbf{ Détection de divergence : }
 \begin{itemize}
\item Utilisez des métadonnées .
\item Vérifiez la surcharge du champ.
\item Vérifiez la règle d'unicité, la règle consécutive et la règle null.
\item Utilisez des outils commerciaux.(data scrubbing (nettoyage) ,Data auditing( detecter des relations o corrélations)
  
   \end{itemize}
	\textbf{ Migration de données et intégration:}
 \begin{itemize}
 \item Outils de migration de données
 \item Outils ETL (Extraction / Transformation / Loading)
 \end{itemize}
\textbf{ Intégration des deux processus:}
 Itératif et interactif 

    \section{Intégration des données}
    \subsection{Problème d'identification d'entité}
     ce problème survient lorsque on à faire à des données collecter de plusieurs sources, l'identification d'entité consiste à retrouver des attributs  qui font référence à la même entité par exemple l'attribut id\_consommateur ou nb\_consommateur mais aussi la détection de différente structure d'un même attribut du diverse sources , généralement on utilise les méta données pour remédier à ce problème
    \subsection{Analyse de redondance et de corrélation}
     Lorsqu'un attribut peut être déduit à partir d'un autre attribut ou plus on dira qu'il est redondant, l'analyse de corrélation permet  de détecter la redondance  on citera :
     \subsubsection{$X^2$ corrélation pour données nominales}
     Pour les données nominales, une relation de corrélation entre deux attributs, A
     et B , peut être découvert par un X2(  chi-carré) test,
     Hypothèse : les deux distributions sont indépendantes
     Les cellules (matrice r colonnes  c lignes) qui contribuent le plus à la valeur X2 sont celles dont le nombre réel (observé) est très différent du nombre attendu .
     Plus la mesure X2 est grande, plus les variables sont susceptibles d'être liées.
     
     
     \begin{equation*}
     X^2 = \sum_{i=1}^{C}\sum_{j=1}^{r}\frac{(o_{ij}- e_{ij})^2}{e_{ij}}
     \end{equation*}
     \begin{equation*}
       e_{ij}= \frac{count(A=a_{i})* count(B=b_{j})}{n}
      \end{equation*}
    
     c : valeurs distinctes que peut prendre l'attribut A
     
     r :valeurs distinctes que peut prendre  l'attribut B
     
     $o_{ij}$: fréquence observé de l'événement commun $A=a_{i},B=b_{j}$
     
     $e_{ij}$: fréquence attendue (prévisible ) de l'événement commun $A=a_{i},B=b_{j}$
      
     n: nombre de tuples totale
      
     count($a_{i}$): nombre de tuple ayant la valeur $a_{i}$ pour A
    
     count( $b_{j}$):nombre de tuple ayant la valeur $b_{j}$ pour B
     
    \subsubsection{Coefficient de corrélation pour les données numériques} 
    coefficient de corrélation de pearson :
    
    \begin{equation*}
    r A,B= \frac{\sum_{i=1}^{n} (a_{i}-\bar{A})(b_{i}-\bar{B})}{n\sigma_{A} \sigma_{B} }= \frac{\sum_{i=1}^{n} (a_{i},b_{i})-n\bar{A}\bar{B}}{n\sigma_{A} \sigma_{B} }
    \end{equation*}
    
    $\bar{A}$:La moyenne des valeurs de l'attribut A.
    
    $\bar{B}$:La moyenne des valeurs de l'attribut B.
    
    $\sigma_{A}$: l'écart type de A
   
    $\sigma_{B}$: l'écart type de B
    
    $\sum_{i=1}^{n} (a_{i},b_{i})$: produit vectoriel
    
    
    r A,B est une mesure entre -1 et 1 si la valeur est positive on dira que A ,B sont positivement corrélé  donc ils augmentent de façon proportionnelle, plus la valeur est proche de  1 plus ils sont corrélé , par contre si la valeur est négative on dira que A,B sont inversement proportionnelle .
    à noter que si r A,B = 0 , A et B sont indépendants
    \subsubsection{Covariance des données numériques}
    Dans la théorie des probabilités et les statistiques, la corrélation et la covariance sont deux mesures similaires.
    
    \begin{equation*}
     E(A)=\bar{A}=\frac{\sum_{i=1}^{n} a_{i}}{n}
    \end{equation*}
        \begin{equation*}
         E(B)=\bar{B}=\frac{\sum_{i=1}^{n} b_{i}}{n}
        \end{equation*}
     La covariance est défini comme :
     \begin{equation*}
     Cov(A,B)=E((A-\bar{A})(B-\bar{B})) = \frac{\sum_{i=1}^{n} (a_{i}-\bar{A})(b_{i}-\bar{B})}{n }
     \end{equation*}
     \begin{equation*}
      r A,B= \frac{Cov(A,B)}{\sigma_{A}\sigma_{B}}
     \end{equation*}
         \begin{equation*}
           Cov(A,B)= E(A.B)-\bar{A}\bar{B}
          \end{equation*}
      Comme la corrélation numérique ,A,B sont dites indépendant alors leurs covariance est nulle , positivement proportionnelle si la covariance est positive et inversement proportionnelle si covariance est négative.
      \subsection{Duplication de tuples}
      c'est lorsqu'il y a deux ou plusieurs tuples identiques pour une donnée en cas de saisie de données unique.
      \subsection{Détection et résolution de conflits de valeurs de données}
     
    L’intégration de données implique également la
    détection et résolution de conflits de valeurs de données
    par exemple pour une même entité du monde réel, les valeurs d'attribut provenant de sources différentes peuvent varier.
     Cela peut être dû à des différences de représentation, de mise à l'échelle ou d'encodage. Par exemple, un  poids (attribut) peut être stocké en unités métriques (kg) dans un système et impériale britannique  dans un autre (pound).
   
    

\end{document}
